# ğŸ©º Diabetes Prediction using KNN


> An end-to-end machine learning project for diabetes prediction using K-Nearest Neighbors. Part of my **ML Notes & Projects** series.

---

## ğŸ“‹ Dataset

| Property | Details |
|:---:|:---:|
| ğŸ“¦ Name | Pima Indians Diabetes Dataset |
| ğŸ‘¥ Samples | 768 patients |
| ğŸ”¢ Features | 8 (Glucose, BMI, Age, etc.) |
| ğŸ¯ Target | 0 = No Diabetes / 1 = Diabetes |

---

## ğŸ§  KNN â€” Theory & Math

> KNN classifies a new point by **majority vote** of its K nearest neighbours.

**ğŸ“ Euclidean Distance**

$$d(x, y) = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}$$

**âš–ï¸ StandardScaler** â€” mandatory for KNN

$$z = \frac{x - \mu}{\sigma}$$

**âœ‚ï¸ IQR Outlier Removal**

$$IQR = Q3 - Q1 \qquad \text{Bounds} = Q1 \pm 1.5 \times IQR$$

**ğŸ” SMOTE Synthesis**

$$x_{new} = x_i + \lambda \times (x_{nn} - x_i)$$

**ğŸ“‰ K-Tuning Error Rate**

$$\text{Error Rate} = \frac{1}{n}\sum_{i=1}^{n} \mathbb{1}(\hat{y}_i \neq y_i)$$

---

## ğŸ”„ ML Pipeline

| # | Step | Purpose |
|---|------|---------|
| 1 | EDA + Heatmap | Understand feature relationships |
| 2 | Zero Imputation | Fix medically invalid entries |
| 3 | IQR Outlier Removal | Remove noisy data points |
| 4 | StandardScaler | Fair distance calculation |
| 5 | Train/Test Split | Unbiased evaluation |
| 6 | SMOTE | Balance minority class |
| 7 | K-Tuning | Find optimal K value |
| 8 | Evaluation | Measure model performance |

---

## ğŸ“ˆ Results

| Model | Accuracy | Macro F1 |
|:-----:|:--------:|:--------:|
| Default K=5 | 71% | 0.69 |
| â­ **Best K=4** | **73%** | **0.71** |

**Confusion Matrix (K=4)**

| | Predicted: 0 | Predicted: 1 |
|--|-------------|-------------|
| **Actual: 0** | 97 âœ… | 30 âŒ |
| **Actual: 1** | 21 âŒ | 43 âœ… |

$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} = 73\%$$

$$\text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}} = 0.71$$

---

## ğŸ’¡ Key Learnings

- âœ… KNN is distance-based â€” scaling is non-negotiable
- âœ… Zeros in medical data = hidden missing values
- âœ… SMOTE prevents bias towards majority class
- âœ… Glucose & BMI are strongest diabetes predictors
- âœ… K-Tuning improved accuracy from 71% â†’ 73%

---

## ğŸ› ï¸ Tech Stack

| Library | Purpose |
|---------|---------|
| pandas | Data manipulation |
| numpy | Numerical operations |
| matplotlib | Plotting |
| seaborn | Statistical visualization |
| scikit-learn | KNN, Scaler, Metrics |
| imbalanced-learn | SMOTE |


---

## ğŸ“ Project Structure

    KNN-Diabetes-Prediction/
    â”‚
    â”œâ”€â”€ ğŸ““ KNN.ipynb       â† Main notebook
    â”œâ”€â”€ ğŸ“Š diabetes.csv    â† Dataset
    â””â”€â”€ ğŸ“„ README.md       â† Documentation

---

<div align="center">

## ğŸ‘¤ Author

**Divyansh Janu**
*Aspiring ML Engineer | ML Notes & Projects*

*â­ Star this repo if you found it helpful!*

</div>
