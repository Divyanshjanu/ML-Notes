# ğŸ”· Support Vector Machine â€“ Red Wine Quality Classification

## ğŸ“Œ Overview

This project implements a complete **Support Vector Machine (SVM)** pipeline to predict red wine quality as a **binary classification** task (**bad** vs **good**). The notebook walks from raw data to a tuned, classâ€‘weighted SVM model, including:

- ğŸ“Š Exploratory Data Analysis (EDA)  
- ğŸ§¹ Targeted outlier removal  
- âš™ï¸ Feature scaling and preprocessing  
- ğŸ” Hyperparameter tuning (Grid & Random search)  
- âœ… Final evaluation with classification reports and confusion matrices  

The objective is to build a wellâ€‘documented, reproducible ML workflow that generalizes well to unseen wine samples.

---

## ğŸ¯ Problem Definition

The original dataset contains physicochemical properties of red wines and a humanâ€‘assigned quality score (integer from 3 to 8). For this project, the `quality` label is transformed into a binary target:

- `0` â†’ **bad** quality wine (scores 2â€“6.5)  
- `1` â†’ **good** quality wine (scores 6.5â€“8)  

The task is to learn a classifier that predicts this binary label from the chemical features.

---

## ğŸ“‚ Dataset

- **Source:** Red wine quality dataset (UCI Wine Quality)  
- **File:** `winequality-red.csv`  
- **Samples:** 1599  
- **Features (11 numeric):**

  - fixed acidity  
  - volatile acidity  
  - citric acid  
  - residual sugar  
  - chlorides  
  - free sulfur dioxide  
  - total sulfur dioxide  
  - density  
  - pH  
  - sulphates  
  - alcohol  

- **Target:**  
  - `quality` (3â€“8) â†’ transformed to `bad` / `good` â†’ encoded as `0` / `1`

**EDA includes:**

- Basic info: `shape`, `info()`, `describe()`  
- Missingâ€‘value check: `isnull().sum()` (no missing values)  
- Class balance: `quality.value_counts()`  
- Visuals: correlation heatmap, histograms, and boxplots for outlier inspection  

---

## ğŸ§ª Methodology

The notebook follows a clear, stepâ€‘byâ€‘step pipeline:

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)

- Inspect data types and summary statistics for all features.  
- Plot a correlation heatmap to see how features relate to `quality`.  
- Draw histograms to observe distributions, skewness, and potential outliers.  
- Use boxplots on the original data to visually highlight extreme values.

---

### 2ï¸âƒ£ Outlier Handling

Outliers are removed **only** from features with strong skew or heavy tails:

- `residual sugar`  
- `chlorides`  
- `free sulfur dioxide`  
- `total sulfur dioxide`  

For each selected feature:

- Compute **Q1**, **Q3**, and **IQR**  
- Define bounds:  
  - **lower** = Q1 âˆ’ 2.0 Ã— IQR  
  - **upper** = Q3 + 2.0 Ã— IQR  
- Filter rows outside `[lower, upper]`

The cleaned dataframe `df_clean` keeps most samples while reducing the impact of extreme values. Updated boxplots confirm that the most severe outliers are removed without destroying the overall distributions.

---

### 3ï¸âƒ£ Target Transformation

The `quality` column is converted to a binary target in three steps:

1. Ensure `quality` is numeric and drop any invalid entries.  
2. Use `pd.cut` to map scores into two bins:

   - (2, 6.5] â†’ `bad`  
   - (6.5, 8] â†’ `good`

3. Apply `LabelEncoder`:

   - `bad` â†’ `0`  
   - `good` â†’ `1`  

This turns the original multiâ€‘class problem into a clean binary classification task.

---

### 4ï¸âƒ£ Featureâ€“Target Split & Scaling

- **Features (`X`):** all 11 numeric physicochemical columns  
- **Target (`y`):** encoded binary `quality` (0 / 1)

Trainâ€“test split:

- 80% training, 20% testing  
- `stratify=y` to preserve class ratios  
- Fixed `random_state` for reproducibility  

Scaling:

- Use `StandardScaler`  
- Fit the scaler on `X_train` only  
- Transform both `X_train` and `X_test` with the fitted scaler  

This avoids data leakage and ensures SVM sees features on a comparable scale.

---

### 5ï¸âƒ£ Baseline SVM Model

A first SVM classifier is trained with:

- `class_weight='balanced'` âš–ï¸ to handle label imbalance  

The baseline model is trained on the scaled training data and evaluated on the test set to establish a reference accuracy before tuning.

---

### 6ï¸âƒ£ Hyperparameter Tuning

To improve performance, the following hyperparameters are tuned:

- `C` (regularization strength)  
- `kernel` (`linear`, `rbf`)  
- `gamma` (`scale`, `auto`, and numeric values)

#### ğŸ”· GridSearchCV

- Exhaustive search over the parameter grid  
- 5â€‘fold crossâ€‘validation  
- Returns `best_model_1` â€“ the best SVM configuration on the training set

#### ğŸ”¹ RandomizedSearchCV (Optional Comparison)

- Random sampling of parameter combinations from the same grid  
- Also uses 5â€‘fold crossâ€‘validation  
- Returns `best_model_2` â€“ another strong candidate model  

Both tuned models are later compared on the test set.

---

### 7ï¸âƒ£ Evaluation

For each tuned model:

- Predict on `X_test`  
- Compute:  
  - âœ… Overall accuracy  
  - ğŸ“„ Classification report (precision, recall, F1, support)  
  - ğŸ”¢ Confusion matrix  

- Plot confusion matrix heatmaps with labelled axes, making it easy to see:

  - True negatives (correctly predicted bad wines)  
  - True positives (correctly predicted good wines)  
  - False positives & false negatives  

**Typical performance (approx.):**

- Test accuracy â‰ˆ **91%**  
- Class `0` (bad): very high precision and recall  
- Class `1` (good): high precision, moderate recall (due to class imbalance)

The model prefers to avoid misclassifying bad wines as good, which is often a reasonable tradeâ€‘off.

---

## ğŸ“ˆ Results Summary

- A classâ€‘weighted SVM with an RBF kernel and tuned `C`/`gamma` achieves the best overall performance.  
- Train and test scores are close, suggesting no strong overfitting.  
- The final model serves as a solid baseline for red wine quality prediction and a clean template for SVM workflows on similar tabular datasets.

---

## ğŸ“ Project Structure

Suggested layout for this folder:

```text
Support_Vector_Machine/
â”œâ”€ SVM.ipynb              # Main notebook with full pipeline
â”œâ”€ winequality-red.csv    # Dataset (if stored locally)
â””â”€ README.md              # Project documentation
